# AI-Security-Usecases
List all use cases that might cause bad or malicious user intent
As of today 19th Oct 2025, I couldn't find a single solution on the internet who claims to provide full security to any of agentic (AI-powered) application publically. I'm going to understand first the malicious known intents (how does a malicious intent looks like) and then will explore the architecture of available agentic applications (apps created using LangGraph or CrewAI) and try to list the possible use cases of each of the agentic application.
With this approach, what I'm going to achieve is:
  - Understanding of adverseral tools (how the tools are designed to do what to achieve the malicious intent)
        - I'll create another folder to record all techniques
  - 2nd, I'll be able to understand the achitecture of Agentic application.
        - If architecture is clear, then I'll map the adverseral techniques to identify the "how-part" (how this tools was designed vulnerable).

The ultimate goal is to provide the solution of this GAP. Like what exactly is required in order to make the agentic application secure.
